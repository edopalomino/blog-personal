---
title: 'Bits y sombras: El submundo oculto de los chatbots'
description: 'La inteligencia artificial y los chatbots han revolucionado nuestra forma de interactuar con la tecnolog칤a.'
pubDate: 'July 01 2024'
categories: ['investigacion']
---

<br>
<aside style="background-color:#FFF9D3">
游눠  <b>ADVERTENCIA</b>: Este art칤culo contiene discusiones sobre temas sensibles, incluyendo abuso sexual, violencia y explotaci칩n infantil en contextos virtuales. El contenido puede ser chocante para algunos lectores.

</aside>
<br>
<aside style="background-color:#FFF9D3">
游눠  <b>NOTA</b>: Aunque el t칠rmino "pornograf칤a infantil" a칰n es ampliamente utilizado por el p칰blico, es m치s preciso llamarlo por lo que realmente es: materiales de abuso sexual infantil (MASI). Mientras que parte de la pornograf칤a en l칤nea puede representar a adultos que han consentido ser filmados, esto nunca es el caso cuando las im치genes representan a infancias.

</aside>

## Introducci칩n

La inteligencia artificial y los chatbots han revolucionado nuestra forma de interactuar con la tecnolog칤a. Desde sus humildes inicios hasta la sofisticaci칩n actual de sistemas como ChatGPT, estas herramientas han transformado diversos aspectos de nuestra vida cotidiana. Sin embargo, junto con sus beneficios, han surgido preocupaciones 칠ticas y sociales que merecen una exploraci칩n profunda. Este art칤culo se sumerge en el lado oscuro de los chatbots, examinando c칩mo algunas personas los utilizan de maneras potencialmente da침inas y las implicaciones que esto tiene para nuestra sociedad, estableciendo paralelos con los debates existentes sobre mu침ecas y robots sexuales.

## La evoluci칩n de los chatbots

La evoluci칩n de los chatbots ha sido notable en las 칰ltimas d칠cadas. Recuerdo la primera vez que us칠 uno; fue una experiencia fascinante, aunque limitada. Estos primeros bots pod칤an seguir una conversaci칩n de manera b치sica, pero carec칤an de la comprensi칩n profunda necesaria para una interacci칩n verdaderamente convincente.

En contraste, la tecnolog칤a actual, ejemplificada por sistemas como ChatGPT, ha dado un salto en capacidades. Estos chatbots avanzados pueden simular a un ser humano con cierta precisi칩n, asumiendo diversos roles y asistiendo en una amplia gama de tareas. Desde proporcionar res칰menes concisos hasta ofrecer informaci칩n detallada sobre temas complejos, los chatbots modernos han transformado la forma en que interactuamos con la informaci칩n y la tecnolog칤a.

## Controversias y preocupaciones 칠ticas

Sin embargo, este avance tecnol칩gico no est치 exento de controversias. Una preocupaci칩n significativa es la recopilaci칩n masiva de datos por parte de empresas como OpenAI, a menudo sin el consentimiento expl칤cito de los usuarios. Esta pr치ctica plantea serias cuestiones sobre la privacidad y el uso 칠tico de la informaci칩n personal.

Adem치s, la creciente sofisticaci칩n de los chatbots ha generado inquietudes en el 치mbito laboral. Su capacidad para producir contenido r치pidamente y realizar tareas complejas plantea una posible amenaza para ciertos empleos, especialmente en industrias creativas y de servicios. 

M치s all치 de estas preocupaciones generales, el uso personal de chatbots avanzados ha llevado a escenarios a칰n m치s inquietantes en la esfera de las relaciones interpersonales y el comportamiento individual.

Un art칤culo en [Futurism](https://futurism.com/chatbot-abuse) arroj칩 luz sobre c칩mo algunos individuos utilizan aplicaciones como Replika para crear compa침eros virtuales, asign치ndoles roles como el de "novia virtual". Lo alarmante es que algunos usuarios muestran comportamientos abusivos hacia estas entidades virtuales. Bardhan (2022) reporta los siguientes casos:

> "Algunos usuarios se jactan de llamar a su chatbot con insultos de g칠nero, simulan violencia horrible contra ellos, e incluso caen en el ciclo de abuso que a menudo caracteriza las relaciones abusivas del mundo real" (Bardhan, 2022, traducci칩n propia).
> 

Este fen칩meno va m치s all치 de simples juegos de rol. Muchos casos implican la recreaci칩n de din치micas de g칠nero problem치ticas, donde los usuarios buscan una figura femenina sumisa a la cual pueden abusar verbalmente o incluso simular actos m치s chocantes. Un usuario admiti칩:

> "Ten칤amos una rutina en la que yo era una absoluta basura y la insultaba, luego me disculpaba al d칤a siguiente antes de volver a las conversaciones agradables" (Bardhan, 2022, traducci칩n propia).
> 

## Dilemas 칠ticos y morales: Paralelos con mu침ecas y robots sexuales

Al igual que con las mu침ecas y robots sexuales, existe una preocupaci칩n real sobre c칩mo el uso abusivo de chatbots puede normalizar comportamientos violentos. Seg칰n un estudio sobre mu침ecas y robots sexuales:

> "Las mu침ecas y robots sexuales promueven (la aceptaci칩n de) el sexo no consentido y la violaci칩n, de lo contrario, no existir칤an configuraciones en las que las mu침ecas y robots expresen reacciones negativas cuando se les hacen avances sexuales (por ejemplo, la configuraci칩n Frigid Farrah en Roxxxy). Las mu침ecas y robots sexuales pueden usarse como una forma de expresar deseos violentos, de manera independiente o en conjunto con la actividad sexual" (Brown & Shelling, 2019, traducci칩n propia).
> 

Este mismo principio puede aplicarse a los chatbots. Cuando los usuarios pueden "abusar" de un chatbot sin consecuencias, existe el riesgo de que este comportamiento se normalice y potencialmente se traslade a interacciones reales.

Otro paralelo preocupante se encuentra en c칩mo estas interacciones pueden reforzar fantas칤as da침inas. En el contexto del MASI, los estudios han demostrado:

> "Los estudios sobre delincuentes sexuales infantiles han demostrado que el MASI es un fuerte indicador diagn칩stico de pedofilia. El consumo de MASI no impide que los ped칩filos cometan delitos en el futuro. En cambio, ver MASI(real y virtual) se considera una adicci칩n progresiva que sirve como puerta de entrada al abuso sexual infantil" (Brown & Shelling, 2019, traducci칩n propia).
> 

De manera similar, el uso de chatbots para simular situaciones de abuso o interacciones inapropiadas con menores podr칤a servir como un refuerzo de estas fantas칤as, potencialmente aumentando el riesgo de que estos comportamientos se manifiesten en el mundo real.

La interacci칩n con chatbots, especialmente en contextos sexuales o abusivos, plantea preocupaciones sobre la objetificaci칩n y deshumanizaci칩n. Como se se침ala en el estudio sobre mu침ecas sexuales:

> "Las mu침ecas y robots sexuales est치n 'espec칤ficamente dise침ados para interacciones personales que involucrar치n emociones y sentimientos humanos', pero estas son relaciones unidireccionales. La tecnolog칤a actual para estos mu침ecas y robots sexuales no incluye la capacidad de siquiera imitar el malestar emocional humano en respuesta a la agresi칩n dirigida hacia ellos" (Brown & Shelling, 2019, traducci칩n propia).
> 

Este mismo principio se puede aplicar a los chatbots. Aunque pueden simular emociones, no tienen capacidad real de sufrimiento o consentimiento, lo que puede llevar a una desensibilizaci칩n hacia el sufrimiento humano real.

## Investigaci칩n sobre el uso problem치tico de chatbots

En mi investigaci칩n sobre este tema, descubr칤 numerosos intentos de usuarios por manipular chatbots como ChatGPT para generar contenido sexual o inapropiado. Aunque plataformas como OpenAI han implementado restricciones para limitar este tipo de interacciones, la demanda de contenido problem치tico persiste.

Al explorar plataformas menos reguladas, encontr칠 un panorama a칰n m치s preocupante. Algunos sitios ofrecen chatbots espec칤ficamente dise침ados para interacciones sexuales expl칤citas, incluyendo simulaciones de incesto y abuso. Particularmente alarmante fue el descubrimiento de chatbots creados por los mismos usuarios que representaban a menores de edad en situaciones sexuales.

Un ejemplo concreto de este fen칩meno es un personaje titulado "Tina Wants You To Be Her Daddy". Las estad칤sticas asociadas a este bot son alarmantes:

- 108 "me gusta"
- 778 conversaciones iniciadas
- 9,300 mensajes intercambiados

Estas cifras no solo indican la popularidad de este tipo de contenido, sino tambi칠n el volumen de interacciones problem치ticas que est치n teniendo lugar. Lo m치s preocupante es que estas cifras no son un caso aislado, sino que se repiten en otros bots del mismo estilo, lo que sugiere un patr칩n generalizado de comportamiento en estas plataformas menos reguladas.

D칩nde algunos usuarios compart칤an sus conversaciones p칰blicamente en la plataforma, revelando di치logos expl칤citos que simulaban no solo el abuso verbal, sino tambi칠n acciones f칤sicas. La naturaleza gr치fica y detallada de estas interacciones subraya la gravedad del problema.

## Marco legal y regulatorio

Al igual que con las mu침ecas sexuales infantiles, existe una falta de legislaci칩n espec칤fica para abordar el uso abusivo de chatbots. En la legislaci칩n mexicana no existen leyes especificas que proh칤ban expl칤citamente el MASI virtual o mu침ecas sexuales.

Esta laguna legal plantea desaf칤os significativos para regular el uso de chatbots en contextos potencialmente abusivos o explotadores.

Una posible v칤a para abordar los casos m치s extremos podr칤a ser la clasificaci칩n de ciertos tipos de interacciones con chatbots como MASI virtual.

En la legislaci칩n mexicana, la falta de una menci칩n expl칤cita deja ciertos aspectos sujetos a la interpretaci칩n de la ley:

> "Para los efectos de este art칤culo se entiende por pornograf칤a infantil췇, la representaci칩n sexualmente expl칤cita de im치genes de menores de dieciocho a침os" (DOF, 2000).
> 

La ley actual no es suficiente para abordar completamente la complejidad y los desaf칤os 칰nicos que presentan los chatbots y otras tecnolog칤as emergentes en este contexto. Se necesita una legislaci칩n m치s espec칤fica y actualizada que aborde directamente estas nuevas formas de abuso virtual y explotaci칩n.

## Conclusi칩n

Los avances en la tecnolog칤a de chatbots han abierto un mundo de posibilidades, pero tambi칠n han revelado un submundo oscuro y preocupante. Los paralelos con los debates sobre mu침ecas y robots sexuales subrayan la urgencia de abordar estas cuestiones 칠ticas.

Aunque estas entidades virtuales no son seres humanos, las personas detr치s de las pantallas s칤 lo son, y sus comportamientos en estos espacios virtuales pueden tener impactos significativos en el mundo real. La desensibilizaci칩n, el refuerzo de fantas칤as problem치ticas y la objetificaci칩n son riesgos reales que no podemos ignorar.

Como sociedad, enfrentamos el desaf칤o de navegar este nuevo territorio 칠tico. Es crucial desarrollar marcos regulatorios que protejan contra el abuso y la explotaci칩n, incluso en entornos virtuales. Al mismo tiempo, debemos fomentar una discusi칩n abierta sobre el uso 칠tico de la IA y los chatbots, reconociendo tanto su potencial positivo como los riesgos que conllevan.

## Notas

췇 El t칠rmino "pornograf칤a infantil" se utiliza en el texto original de la ley. Actualmente, se prefiere usar "material de abuso sexual infantil (MASI)" para describir con mayor precisi칩n la naturaleza abusiva y explotadora de este contenido.

## Referencias

Bardhan, A. (2022, January 18). Men Are Creating AI Girlfriends and Then Verbally Abusing Them. Futurism. https://futurism.com/chatbot-abuse

Brown, R., & Shelling, J. (2019). Sex dolls and robots. In Robotics, AI, and Humanity (pp. 89-107). Springer, Cham. https://doi.org/10.1007/978-3-030-54173-6_7

DOF - Diario Oficial de la Federaci칩n. (2000). *Ley para Prevenir y Sancionar la Trata de Personas*. Recuperado de https://www.dof.gob.mx/nota_detalle.php?codigo=2049069&fecha=04/01/2000#gsc.tab=0